{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically search for an NVIDIA GPU and use it. If not, then use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('/global/u2/q/qingyanz/cgcnn')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of our preprocessed and split data from our cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('../preprocessing/sdt/feature_dimensions.pkl', 'rb') as file_handle:\n",
    "    orig_atom_fea_len, nbr_fea_len = pickle.load(file_handle)\n",
    "\n",
    "with open('../preprocessing/splits.pkl', 'rb') as file_handle:\n",
    "    splits = pickle.load(file_handle)\n",
    "\n",
    "sdts_train, sdts_val = splits['sdts_train'], splits['sdts_val']\n",
    "targets_train, targets_val = splits['targets_train'], splits['targets_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "['/global/project/projectdirs/m2755/GASpy_workspaces/GASpy/GASpy_regressions', '/global/project/projectdirs/m2755/GASpy_workspaces/GASpy/GASpy_feedback', '/global/project/projectdirs/m2755/GASpy_workspaces/GASpy', '', '/opt/ovis/lib/python2.7/site-packages', '/global/homes/k/ktran/miniconda3/envs/gaspy/lib/python36.zip', '/global/homes/k/ktran/miniconda3/envs/gaspy/lib/python3.6', '/global/homes/k/ktran/miniconda3/envs/gaspy/lib/python3.6/lib-dynload', '/global/homes/k/ktran/miniconda3/envs/gaspy/lib/python3.6/site-packages', '/global/homes/k/ktran/miniconda3/envs/gaspy/lib/python3.6/site-packages/IPython/extensions', '/global/u2/q/qingyanz/.ipython', '/global/u2/q/qingyanz/cgcnn']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "print(os.path.exists('../preprocessing/feature_dimensions.pkl'))\n",
    "print(os.path.exists('../preprocessing/splits.pkl'))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the CGCNN `net` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import skorch.callbacks.base\n",
    "from skorch import callbacks  # needs skorch >= 0.4  \n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.dataset import CVSplit\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "from cgcnn.data import collate_pool, MergeDataset\n",
    "\n",
    "\n",
    "# Callback to checkpoint parameters every time there is a new best for validation loss\n",
    "cp = callbacks.Checkpoint(monitor='valid_loss_best', fn_prefix='valid_best_')\n",
    "\n",
    "# Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('valid_best_params.pt')\n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "\n",
    "# Callback to set the learning rate dynamically\n",
    "LR_schedule = callbacks.lr_scheduler.LRScheduler('MultiStepLR', milestones=[100], gamma=0.1)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len=orig_atom_fea_len,\n",
    "    module__nbr_fea_len=nbr_fea_len,\n",
    "    batch_size=214,\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs=150,\n",
    "    module__atom_fea_len=46,\n",
    "    module__h_fea_len=83,\n",
    "    module__n_conv=8,\n",
    "    module__n_h=4,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn=collate_pool,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn=collate_pool,\n",
    "    iterator_valid__shuffle=False,\n",
    "    device=device,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a new model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, classification, h_fea_len, n_conv, n_h, nbr_fea_len, orig_atom_fea_len.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1        \u001b[36m0.5684\u001b[0m        \u001b[32m0.9403\u001b[0m     +  21.5256\n",
      "      2        \u001b[36m0.3422\u001b[0m        \u001b[32m0.5739\u001b[0m     +  20.7066\n",
      "      3        \u001b[36m0.2680\u001b[0m        \u001b[32m0.2394\u001b[0m     +  20.6780\n",
      "      4        0.2883        0.3452        20.7629\n",
      "      5        \u001b[36m0.2523\u001b[0m        \u001b[32m0.2179\u001b[0m     +  20.6928\n",
      "      6        0.2548        \u001b[32m0.2072\u001b[0m     +  20.6906\n",
      "      7        \u001b[36m0.2381\u001b[0m        0.2266        20.7190\n",
      "      8        0.2464        0.2329        20.5347\n",
      "      9        \u001b[36m0.2336\u001b[0m        0.2880        20.6136\n",
      "     10        \u001b[36m0.2078\u001b[0m        \u001b[32m0.2067\u001b[0m     +  20.6775\n",
      "     11        0.2160        \u001b[32m0.1932\u001b[0m     +  20.7319\n",
      "     12        0.2181        \u001b[32m0.1889\u001b[0m     +  20.7769\n",
      "     13        0.2218        0.2256        20.7402\n",
      "     14        0.2201        0.1894        20.7006\n",
      "     15        \u001b[36m0.2062\u001b[0m        0.2649        20.6762\n"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.fit(sdts_train, targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or load whatever is cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize()\n",
    "net.load_params(f_history='valid_best_history.json',\n",
    "                f_optimizer= 'valid_best_optimizer.pt', \n",
    "                f_params='valid_best_params.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Calculate the error metrics\n",
    "targets_pred = net.predict(sdts_val).reshape(-1)\n",
    "mae = mean_absolute_error(targets_val, targets_pred)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val, targets_pred))\n",
    "r2 = r2_score(targets_val, targets_pred)\n",
    "\n",
    "# Report\n",
    "print('MAE = %.2f eV' % mae)\n",
    "print('RMSE = %.2f eV' % rmse)\n",
    "print('R^2 = %.2f' % r2)\n",
    "\n",
    "with open('single_cgcnn.pkl', 'wb') as saveplot:\n",
    "    pickle.dump((targets_pred, mae, rmse, r2), saveplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Calculate the error metrics\n",
    "targets_pred = net.predict(sdts_val).reshape(-1)\n",
    "mae = mean_absolute_error(targets_val, targets_pred)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val, targets_pred))\n",
    "r2 = r2_score(targets_val, targets_pred)\n",
    "\n",
    "# Report\n",
    "print('MAE = %.2f eV' % mae)\n",
    "print('RMSE = %.2f eV' % rmse)\n",
    "print('R^2 = %.2f' % r2)\n",
    "\n",
    "# Plot\n",
    "lims = [-4, 2]\n",
    "grid = sns.jointplot(targets_val.reshape(-1), targets_pred,\n",
    "                     kind='hex',\n",
    "                     bins='log',\n",
    "                     extent=lims+lims)\n",
    "_ = grid.ax_joint.set_xlim(lims)\n",
    "_ = grid.ax_joint.set_ylim(lims)\n",
    "_ = grid.ax_joint.plot(lims, lims, '--')\n",
    "_ = grid.ax_joint.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = grid.ax_joint.set_ylabel('CGCNN $\\Delta$E [eV]')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaspy_ktran",
   "language": "python",
   "name": "gaspy_ktran"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
